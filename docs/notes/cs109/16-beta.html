<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Knowledge – beta</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Knowledge</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">Home</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes.html">Stanford Notes</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#lecture-16---beta" id="toc-lecture-16---beta" class="nav-link active" data-scroll-target="#lecture-16---beta">Lecture 16 - Beta</a>
  <ul class="collapse">
  <li><a href="#probability-as-a-random-variable" id="toc-probability-as-a-random-variable" class="nav-link" data-scroll-target="#probability-as-a-random-variable">Probability as a random variable</a></li>
  <li><a href="#beta-random-variable" id="toc-beta-random-variable" class="nav-link" data-scroll-target="#beta-random-variable">Beta random variable</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#frequentist-vs.-bayesian" id="toc-frequentist-vs.-bayesian" class="nav-link" data-scroll-target="#frequentist-vs.-bayesian">Frequentist vs.&nbsp;bayesian</a></li>
  <li><a href="#ok-back-to-the-lecture-at-5000" id="toc-ok-back-to-the-lecture-at-5000" class="nav-link" data-scroll-target="#ok-back-to-the-lecture-at-5000">Ok… back to the lecture at <code>50:00</code>:</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="lecture-16---beta" class="level1">
<h1>Lecture 16 - Beta</h1>
<p>Date of when lecture was given: <code>02/11/22</code>.</p>
<p>We now begin discussion of an entire new unit: <strong>uncertainty theory</strong>. We will have a meta discussion about probabilities: what happens when there is uncertainty in our probabilities themselves?! We need some sort of measure to quantify uncertainty. Unless you have been sleeping under a rock this entire quarter, this should scream: “probability is the measure of uncertainty”. Yes. Yes, that is right. We will use probabilities to measure the uncertainty of other probabilities (via random variables). This is the most theoretical and therefore most mathematical part of the course.</p>
<section id="probability-as-a-random-variable" class="level3">
<h3 class="anchored" data-anchor-id="probability-as-a-random-variable">Probability as a random variable</h3>
<ul>
<li><p><strong>Example</strong>: You ask about the probability of rain tomorrow. Person A: My leg itches when it rains and its kind of itchy…. Uh, <span class="math inline">\(p = .80\)</span>. Person B: I have done precise, complex calculations and have seen 10,451 days like tomorrow… <span class="math inline">\(p = 0.80\)</span>. What is the difference between the two estimates?</p></li>
<li><p><strong>Example</strong>: you are buying an item on Amazon and are deciding between two different models. The first model has all 5-star ratings! Woohoo! And the second model has an average of 4.3 stars. Easy decision right? Wrong. It turns out the 5-star rating has only 5 reviewers whereas the second model has over thousands of reviewers. Which one do you choose now? This type of uncertainty in our belief for each item model is what we will discuss today.</p></li>
<li><p><strong>Remark</strong>: Until now probabilities have just been numbers in the range 0 to 1. However, if we have uncertainty about our probability, it would make sense to represent our <strong>probabilities as random variables</strong> (and thus articulate the relative likelihood of our belief).</p></li>
</ul>
<p>We introduce the beta random variable in this light via annotated example.</p>
</section>
<section id="beta-random-variable" class="level3">
<h3 class="anchored" data-anchor-id="beta-random-variable">Beta random variable</h3>
<p>Say we have some coin and we want to know the probability, <span class="math inline">\(p\)</span>, that it will turn up as heads (the age old question). We flip the coin a total of <span class="math inline">\(n+m\)</span> times where <span class="math inline">\(n\)</span> is the number of heads and <span class="math inline">\(m\)</span> is the number of tails (so <span class="math inline">\(n+m\)</span> is all flips). And so we have</p>
<p><span class="math display">\[p=\frac{n}{n+m}.\]</span></p>
<p>But is this really true? What if we only flip the coin 3 times total? We might get something like <span class="math inline">\(p \approx 0.33333\)</span>. Are we really certainly about our belief in this probability? Can you guess what I am hinting it (uncertainty in our belief!)? This number (<span class="math inline">\(p=\frac{n}{n+m}\)</span>) doesn’t capture our uncertainty about <span class="math inline">\(p\)</span> itself. So just like anything with uncertainty, we propose to capture such semantics via a <strong>distribution for the values</strong> that <span class="math inline">\(p\)</span> can take on.</p>
<p>Recall that we defined a random variable as something that can take on different values at different probabilities. To formalize the idea that we want a distribution for <span class="math inline">\(p\)</span>, we are going to use a random variable <span class="math inline">\(X\)</span> to represent the <strong>probability</strong> of the coin coming up heads. And so we can define probabilities that <span class="math inline">\(X\)</span> takes on a certain probability. Probability is a continious measure and has a range (support) between 0 and 1.</p>
<p>And so without any prior belief in what <span class="math inline">\(X\)</span> can be, we assume that each value that <span class="math inline">\(X\)</span> can take on is equally likely (that is, we assume <span class="math inline">\(X\)</span> can take on any probability at an equally likely rate). For this reason, we start by saying</p>
<p><span class="math display">\[X \sim U n i(0,1).\]</span></p>
<p>Now how do we “<strong>update our beliefs about a random variable/probability</strong>”?! You got it. Bayes’ theorem. So we wil condition on another random variable that represents the new observations. For the Beta distribution, we condition on Binomials (take a moment to understand this: you are conditioning on an entirely separate distribution… how you obtain that distribution can be through frequentist experiment trials or be given the distribution predeterminedly).</p>
<p>Say we start to flip the coin a few times now and we want to update our beliefs (probabilities) for <span class="math inline">\(X\)</span>. This is actually a whole experiment in it of itself. And so let <span class="math inline">\(N\)</span> be a random variable that represents the number of heads that can come up, given that the coin flips are independent. So we define our binomial. But of course, we need to plug in a parameter <span class="math inline">\(p\)</span> for our binomial so we actually condition on <span class="math inline">\(X\)</span> itself first. That is,</p>
<p><span class="math display">\[(N \mid X) \sim \operatorname{Bin}(n+m, x).\]</span></p>
<p><em>Recall that the little <span class="math inline">\(x\)</span> is a probability</em>. So we now apply Bayes’ theorem to update our belief in <span class="math inline">\(X\)</span> given the new Binomial distribution for <span class="math inline">\(X\)</span> (specifically we want to calculate the PDF distribution for <span class="math inline">\(X\)</span> given <span class="math inline">\(N\)</span>):</p>
<p><img src="attachments/Pasted%20image%2020220303195029.png" class="img-fluid"></p>
<p>Now notice one specific thing. Remember that each component of Bayes’ theorem has a name:</p>
<p><img src="attachments/Pasted%20image%2020220303195057.png" class="img-fluid"></p>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>So in summary, we stated that we might have uncertainty in our beliefs (probabilities) themselves. Thus, we decided to represent probability as a random variable, <span class="math inline">\(X\)</span>. Now we aimed to find a parametric distribution for the random variable. Initially, we started with a uniform distribution: <span class="math inline">\(X \sim U n i(0,1)\)</span> where the value that <span class="math inline">\(X\)</span> can take on is equally likely. But of course, we want to update such a belief for <span class="math inline">\(X\)</span> given some observed experimental trials (or expert knowledge). So we use conditional probability in the form of Bayes’ theorem. In this case, we condition on a Binomial RV, <span class="math inline">\(N\)</span> (i.e.&nbsp;coin flips experiment).</p>
<p><span class="math display">\[
f_{X \mid N}(x \mid n)=\frac{P(N=n \mid X=x) f_{X}(x)}{P(N=n)}
\]</span></p>
<p>But realize that we have a prior! A lot of times we can just keep this as a uniform because we may not know any previous knowledge beforehand. But sometimes we do. For example, we may know that a certain drug is likely to work to a certain degree based on expert knowledge. And to incorporate such knowledge of this in the calculation, we can define the prior as such. Notice that the prior is also an RV PDF (i.e.&nbsp;<span class="math inline">\(f_{X}(x)\)</span>) which represents the initial beliefs in our probabilities (so in some way this is recursion but it really isn’t because we are usually given such information). That is, we incorporate such domain knowledge via a probability density function which represents the beliefs in the probabilitied for <span class="math inline">\(X\)</span> initially (“prior information”). This is the thing we are updating! To this in it of itself can be any RV that has range <span class="math inline">\([0,1]\)</span> which leaves us with either a beta RV and uniform RV. And so if we have some prior non-uniform belief, we must use a beta to represent that belief! So yes, We are using a beta RV to derive the PDF for the beta. But don’t worry, this isn’t recursion because you’d usually be given such a beta or at least the information needed to describe and therefore denote it (i.e.&nbsp;through expert domain knowledge or repeated experimentation). Note that such a property is called a <strong>conjugacy</strong>: we are deriving the posterior from the same distribution family in the prior.</p>
<p>Ok… so we have the idea and intuition down: we need our prior to be a beta. But we haven’t even given the derivation for a beta yet. We mentioned that this information is gained by things like expert knowledge or repeated trials. We will talk about deriving the beta for the latter (the former is usually given).</p>
<blockquote class="blockquote">
<p>We flip a fair coin defined as X ~ Uni(0, 1) prior over probability, and observe: <span class="math inline">\(n\)</span> “successes” and <span class="math inline">\(m\)</span> “failures”. By the Binomial distribution, our new belief in <span class="math inline">\(X\)</span> is <span class="math display">\[
f_{X}(x)=\frac{1}{c} \cdot x^{n}(1-x)^{m}.
\]</span> where <span class="math inline">\(c=\int_{0}^{1} x^{n}(1-x)^{m}\)</span>. And so plugging this in as our prior in the original Bayes’ derivation above, we have <span class="math display">\[
\begin{aligned}
f(X=x \mid N=n) &amp;=\frac{P(N=n \mid X=x) f(X=x)}{P(N=n)} \\
&amp;=\frac{\left(\begin{array}{c}
n+m \\
n
\end{array}\right) x^{n}(1-x)^{m} f(X=x)}{P(N=n)} \\
&amp;=\frac{\left(\begin{array}{c}
n+m \\
n
\end{array}\right) x^{n}(1-x)^{m} \frac{1}{B(a, b)} x^{a-1}(1-x)^{b-1}}{P(N=n)} \\
&amp;=K_{1} \cdot\left(\begin{array}{c}
n+m \\
n
\end{array}\right) x^{n}(1-x)^{m} \frac{1}{B(a, b)} x^{a-1}(1-x)^{b-1} \\
&amp;=K_{3} \cdot x^{n}(1-x)^{m} x^{a-1}(1-x)^{b-1} \\
&amp;=K_{3} \cdot x^{n+a-1}(1-x)^{m+b-1} \\
X \mid N &amp; \sim \operatorname{Beta}(n+a, m+b)
\end{aligned}.
\]</span></p>
</blockquote>
<blockquote class="blockquote">
<p>PDF: <span class="math display">\[
f(x)=B \cdot x^{a-1} \cdot(1-x)^{b-1}.
\]</span></p>
</blockquote>
<p>There you have it folks: the beta random variable derived by conditioning a uniform on a Binomial! See <a href="https://en.wikipedia.org/wiki/Beta-binomial_distribution">here</a> and <a href="https://en.wikipedia.org/wiki/Beta_distribution">here</a>.</p>
<blockquote class="blockquote">
<p><strong>Summary</strong>: ok… now a real short and sweet summary. We want a random variable to measure our beliefs in the some binomially distributed process (e.g.&nbsp;coin flips). We start by defining <span class="math inline">\(X\)</span> as a uniform: <span class="math inline">\(X ~ Uni(0, 1)\)</span>. Now we perform some experiment (i.e.&nbsp;flipping the coin some number of times) which gives us a binomial RV, <span class="math inline">\(N\)</span>. We condition <span class="math inline">\(X\)</span> on <span class="math inline">\(N\)</span> to update our beliefs about <span class="math inline">\(X\)</span>: <span class="math display">\[
f(X=x \mid N=n)=\frac{P(N=n \mid X=x) f(X=x)}{P(N=n)}
\]</span></p>
</blockquote>
<hr>
<section id="more-notes" class="level4">
<h4 class="anchored" data-anchor-id="more-notes">More notes</h4>
<ul>
<li>Random variable for measuring probabilities
<ul>
<li>So you have a distribution of probabilities</li>
<li>Support is 0 to 1.
<ul>
<li>Probability… so it is continuous</li>
</ul></li>
</ul></li>
<li>The input parameters are like a Binomial experiment. For example, we flip a coin 10 times and it comes up heads 7/10 times and tails 3/10 times. So what is our distribution of probabilities that such a random variable can take on? Well, certainly given the observed data, we see that the most likely probability should be 7/10.</li>
<li>So we now have a distribution of probabilities for each of the probabilities that the coin can take on (and thus articulate the relative likelihood of our belief).</li>
</ul>
</section>
</section>
<section id="frequentist-vs.-bayesian" class="level3">
<h3 class="anchored" data-anchor-id="frequentist-vs.-bayesian">Frequentist vs.&nbsp;bayesian</h3>
<p>Two schools of thought and it boils down to a component of an equation.</p>
<ul>
<li>In the coin flips example, we can simulate billions of coin flips instantly and approach the problem from a frequentist point of view (<span class="math inline">\(\frac{m}{m+n}\)</span>). However…</li>
<li>We might want to assign a Beta random variable that represents the probability of a medical drug working. We cannot simulate this on billions of people. So we have to use our expert domain prior knowledge about the world somehow. This is the Bayesian world view.</li>
<li>See <code>50:00</code> of lecture 16.</li>
</ul>
<p>Take this example:</p>
<hr>
<ul>
<li><p>When we use beta as a prior, we don’t need to do the above derivation because the posterior is from the same distribution. So all we need to do is add the number of successes and number of failures to our prior parameters for beta and we get the newly defined posterior. The derivation works out to be <span class="math inline">\(\operatorname{Beta}(a+h, b+t)\)</span> where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are the original parameters and <span class="math inline">\(h\)</span> and <span class="math inline">\(t\)</span> are the updated number of successes and failures.</p></li>
<li><p>Application: You might be asked to calculate the updated belief in <span class="math inline">\(X\)</span>, already defined as a beta of the form <span class="math inline">\(\operatorname{Beta}(a, b)\)</span> given <span class="math inline">\(h+t\)</span> new trials where <span class="math inline">\(h\)</span> is number of new successes and <span class="math inline">\(t\)</span> is number of new failures. So the new RV is just <span class="math inline">\(\operatorname{Beta}(a+h, b+t)\)</span>. Derivation is given in course reader but it is just a repeated application of Bayes’ theorem.</p></li>
<li><p>In our original derivation for the beta, we conditioned <span class="math inline">\(X \sim Uni(0, 1)\)</span> on <span class="math inline">\((N \mid X) \sim \operatorname{Bin}(n+m, x)\)</span> which gave us the PDF for a beta: <span class="math display">\[f(X=x)=\left\{\begin{array}{ll}\frac{1}{B(a, b)} x^{a-1}(1-x)^{b-1} &amp; \text { if } 0&lt;x&lt;1 \\ 0 &amp; \text { otherwise }\end{array} \quad\right.$ where $B(a, b)=\int_{0}^{1} x^{a-1}(1-x)^{b-1} d x\]</span></p></li>
<li><p>Now we can continiously update our belief on <span class="math inline">\(X\)</span> with other RVs as priors but if that new prior happens to be a beta… our update is very simple!: <span class="math display">\[\operatorname{Beta}(a, b) \rightarrow \operatorname{Beta}(a+h, b+t). \]</span></p>
<p>Note: the original derivation for the beta was done by updating a uniform conditioned on a binomial. Here we condition a beta on a binomial (and so our prior is a beta and we actually end up with another beta which is our posterior).</p></li>
<li><p>Another note: if the posterior is the same as the prior (i.e.&nbsp;conjugacy), you should realize that all you are doing is updating the parameters.</p></li>
</ul>
<hr>
</section>
<section id="ok-back-to-the-lecture-at-5000" class="level2">
<h2 class="anchored" data-anchor-id="ok-back-to-the-lecture-at-5000">Ok… back to the lecture at <code>50:00</code>:</h2>
<ul>
<li>Can use laplace prior instead of uniform to prevent probability being 0. Can be nicer in code.</li>
<li>Imagine a scenario where we need to decide betwe en two drugs to give to patients. Let us say we have two beta distributions that represent the probabilities that each drug is a success. We can use a greedy approach that is referred to as <strong>Thompson sampling</strong>. It goes like this. Sample from your first beta distribution (giving a probability). Now sample from your second beta distribution (giving you another probability). You should choose the drug whose sample was a higher probability. Why? Because the confidence is higher in that drug (see around <code>1:15</code> for a more detailed explanation).
<ul>
<li>This allows us to make good decisions “under uncertainty”.</li>
<li>This has a whole host of applications such as in RL for game-playing agents (which path should I take in chess?).
<ul>
<li>A lot of these algorithms though use similar, but more complex RL algorithms.</li>
</ul></li>
</ul></li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>