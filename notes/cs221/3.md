# Week 2, Lecture 1 - Machine Learning II

`Date: 10/3/22` 


## Module: Group DRO

> "How to ensure more equitable performance." 

- **Motivation**:
  - Thus far, our goal has been to minimize training loss with the hope that our model will perform well on new examples. 
  - However, train loss is defined as the average of all individual losses on each sample. 
  - Equally weighting every sample loss can lead to problems with equity. 
  - For example, unrepresented groups in the training data will have less representation in the loss and therefore in the model. 
  - group distributional robust optimization (group DRO) can help mitigate some of these inequalities. 
  - tl;dr: averaging training losses can lead to inequalities across groups, group DRO can help mitigate this. 

- **Example**:
  - Gender Shades project by Joy Buolamwini and Timnit Gebru discovered that Microsoft, Face++, and IBM's gender classification system performed worse on darker-skinned females, while lighter-skinned data samples got nearly 100% accuracy. 
    - i.e., discrimination can arise from ML 
  - Has real life consequences: "Robert Julian-Borchak Williams was wrongly arrested due to a incorrect match with another Black man captured from a surveillance video, and this mistake was made by a facial recognition system". 
  
How can we help mitigate this algorithmically? 

### Linear regression the standard way 

Take the following dataset, where each sample now as an addtional meta-datum: a group (e.g., some demographic). 

<p align='center'>
    <img alt="picture 1" src="https://cdn.jsdelivr.net/gh/minimatest/vscode-images/images/203a10115a09ff5f74c0cdc06106bcd6d5d683946084e8bfa78f6cb4862644ec.png" width="75" />  
</p>

Let's setup the same model we used in last lecture's linear regression module: 

$$
f_{\mathbf{w}}(x)=\mathbf{w} \cdot \phi(x) \quad \mathbf{w}=[w] \quad \phi(x)=[x]
$$

> Important note: we don't use (i.e., the predictor $f_{\mathbf{w}}$) does not use group information $g$ to make a prediction. 

And since this is linear regression, all models will be a line that passes through the origin, differing in the slope $w$. Here is a plot of the training samples with the identity line: 

<p align='center'>
    <img alt="picture 3" src="https://cdn.jsdelivr.net/gh/minimatest/vscode-images/images/f35e283529f869898fc49472936d28da35fd65511dd58be434ea94a901246faf.png" width="300" />  
</p>

As we can see, certain values for $w$ will be more beneficial for the blue group than the orange group. There is a bit of tension. 

The classic way to solve a linear regression problem here is to minimize the train loss which is an **average** over all sample losses: 

$$
min \operatorname{TrainLoss}(\mathbf{w})=\frac{1}{\left|\mathcal{D}_{\text {train }}\right|} \sum_{(x, y) \in \mathcal{D}_{\text {train }}} \operatorname{Loss}(x, y, \mathbf{w})
$$


with the above data points (and $\operatorname{Loss}(x, y, \mathbf{w})=\left(f_{\mathbf{w}}(x)-y\right)^2$), we have: 

$$
\operatorname{TrainLoss}(1)=\frac{1}{6}\left((1-4)^2+(2-8)^2+(5-5)^2+(6-6)^2+(7-7)^2+(8-8)^2\right)=7.5. 
$$

doing some calculations, we see that $\mathbf{w}=1.09$ produces the minimum train loss: 

<p align='center'>
    <img alt="picture 5" src="https://cdn.jsdelivr.net/gh/minimatest/vscode-images/images/8af2e036628b68f4d09559683fc2c6efeee466a62848b36b168d48ca5f7c3527.png" width="200" />  
</p>

### Using groups 

Ok... let's change one thing up (loss!) a couple of times. 

> **Let's calculate the loss for each group separately**. 

#### Per-group loss


From above, we define the train loss for some general group $g$ as 

$$
\operatorname{TrainLoss}_g(\mathbf{w})=\frac{1}{\left|\mathcal{D}_{\text {train }}(g)\right|} \sum_{(x, y) \in \mathcal{D}_{\text {train }}(g)} \operatorname{Loss}(x, y, \mathbf{w}).
$$ 

plugging in for the above dataset: 

$$\operatorname{TrainLoss}_{\mathrm{A}}(1)=\frac{1}{2}\left((1-4)^2+(2-8)^2\right)=22.5$$

$$\operatorname{TrainLoss}_{\mathrm{B}}(1)=\frac{1}{4}\left((5-5)^2+(6-6)^2+(7-7)^2+(8-8)^2\right)=0$$

> **Conclusion**: huge performance drop-off from 0 to 22.5 loss for the underrepresented group (A). So, although the average loss is 7.5, we see the disparity for ourselves here. Many people won't go this deep and assume their "7.5" loss is good enough. 


Also, check this out: 

<p align='center'>
    <img alt="picture 6" src="https://cdn.jsdelivr.net/gh/minimatest/vscode-images/images/82657168bc8bda0c533b977607a98e1548df8361a95946696ee0ea9f508d3b15.png" width="300" />  
</p>

see how the minimum for group A and group B mean picking different values for $\mathbf{w}$. But of course, we can only pick one $\mathbf{w}$. Tension, tension! 

Ok cool... but usually it is helpful to have just *one* value for the loss. I agree: 

#### Maximum group loss

We can literally just perform per-group losses and just take the max of all of them (i.e., the worst case): 

$$
\operatorname{TrainLoss}_{\max }(\mathbf{w})=\max _g \operatorname{TrainLoss}_g(\mathbf{w}).
$$

<p align='center'>
    <img alt="picture 7" src="https://cdn.jsdelivr.net/gh/minimatest/vscode-images/images/68003fb50fdb35b72c8b4e494e9bad33f352b4736f5e8b8720b51da77f32408a.png" width="300" />  
</p>

This function is the pointwise maximum of the per-group losses, which you can see on the plot as taking the upper envelope of the two per-group losses (cs 221).  

We call this group distributionally robust optimization. 

#### Average vs. group DRO 

Alright... here are the results: 

<p align='center'>
    <img alt="picture 8" src="https://cdn.jsdelivr.net/gh/minimatest/vscode-images/images/c52ed0799b4138af07d7659332457f601131fc24b0e8d012a18c1e27d72aaabf.png" width="300" />  
</p>

Here, a weight vector $\mathbf{w}=1.09$ minimizes the loss for the average (traditional) case. However, using group DRO, we get $\mathbf{w}=1.58$. So using $\mathbf{w}=1.58$ might produce worse results but should be more equitable (see the learned purple line vs. the learning red line). 

> "Intuitively, the average loss favors majority groups over minority groups, but the maximum group loss gives a stronger voice to the minority groups, and as we see here, their influence is felt to a greater extent." - CS 221. 


#### Note on gradient descent 

From the 221 slides: 

- In general, we can minimize the maximum group loss by gradient descent, as usual.
- We just have to be able to take the gradient of TrainLoss $_{\max }$ , which is a maximum over the per-group losses.
- The gradient of a max is simply the gradient of the term that achieves the max.
- So algorithmically, it's very intuitive: you first compute whichever group ($g^*$) has the highest loss, and then you just evaluate the gradient only on per-group loss of that group ($g^*$). 

In math: 

$$
\begin{aligned}
&\operatorname{TrainLoss}_{\max }(\mathbf{w})=\max _g \operatorname{TrainLoss}_g(\mathbf{w}) \\
&\nabla \operatorname{TrainLoss}_{\max }(\mathbf{w})=\nabla \operatorname{TrainLoss} g_{g^*}(\mathbf{w}) \\
&\text { where } g^*=\arg \max _g \operatorname{TrainLoss}_g(\mathbf{w})
\end{aligned}. 
$$

Note that SGD cannot be applied in vanilla form since its not an average, it is a max of an average[^1]. 

[^1]: I don't think I comprehend [this](https://stanford-cs221.github.io/autumn2022/modules/module.html#include=machine-learning%2Fgroup-dro.js&slideId=training-via-gradient-descent-prose&level=0) well enough. 

Some other notes to consider: 
- When we have multiple attributes (gender, race), intersectionality becomes difficult to incorporate. 
- For further reading, consider checking out the book [Fairness and machine learning: Limitations and Opportunities](https://fairmlbook.org/), and a [paper](https://arxiv.org/pdf/1911.08731.pdf) that explores group DRO for neural networks. 



## Module: Non-linear features (offline) 

## Module: Feature templates (offline) 

## Module: Neural networks

## Module: Backpropagation 

## Module: Differentiable programming (optional) 





